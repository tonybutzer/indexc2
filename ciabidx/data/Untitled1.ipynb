{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-02 19:25:08 cf-templates-k60v3e6ss69n-us-west-2\r\n",
      "2017-10-24 01:18:52 cloudsploitlambda-471850042218\r\n",
      "2017-07-18 14:20:35 erosodc1\r\n",
      "2019-07-17 10:43:40 ga-africa-provisional\r\n",
      "2018-10-31 04:32:27 ga-autobots-elk-471850042218-logsstac-trailbucket-rk21t6aox8cf\r\n",
      "2019-09-03 00:55:08 ga-config-471850042218\r\n",
      "2017-08-31 22:23:35 ga-odc-eros-archive-west\r\n",
      "2019-05-02 17:11:57 ga-odc-eros-kops-west\r\n",
      "2018-07-25 07:15:30 guarddutyslacklambda-471850042218\r\n",
      "2019-10-16 04:41:24 guarddutyteamslambda-471850042218\r\n",
      "2017-05-26 00:29:35 lcmap-washington-state\r\n",
      "2018-02-07 22:28:56 usgs-devs-tfstate\r\n"
     ]
    }
   ],
   "source": [
    "! aws s3 ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untitled.ipynb\tUntitled1.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: awscli in ./.local/lib/python3.6/site-packages (1.16.290)\n",
      "Requirement already satisfied: colorama<0.4.2,>=0.2.5; python_version != \"2.6\" and python_version != \"3.3\" in ./.local/lib/python3.6/site-packages (from awscli) (0.4.1)\n",
      "Requirement already satisfied: rsa<=3.5.0,>=3.1.2 in ./.local/lib/python3.6/site-packages (from awscli) (3.4.2)\n",
      "Requirement already satisfied: botocore==1.13.26 in ./.local/lib/python3.6/site-packages (from awscli) (1.13.26)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from awscli) (0.14)\n",
      "Requirement already satisfied: PyYAML<5.2,>=3.10; python_version != \"2.6\" and python_version != \"3.3\" in /usr/local/lib/python3.6/dist-packages (from awscli) (3.12)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from awscli) (0.2.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<=3.5.0,>=3.1.2->awscli) (0.4.7)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20; python_version >= \"3.4\" in /usr/local/lib/python3.6/dist-packages (from botocore==1.13.26->awscli) (1.24.2)\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore==1.13.26->awscli) (2.7.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from botocore==1.13.26->awscli) (0.9.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"->botocore==1.13.26->awscli) (1.12.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install --user awscli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-02 19:25:08 cf-templates-k60v3e6ss69n-us-west-2\n",
      "2017-10-24 01:18:52 cloudsploitlambda-471850042218\n",
      "2017-07-18 14:20:35 erosodc1\n",
      "2019-07-17 10:43:40 ga-africa-provisional\n",
      "2018-10-31 04:32:27 ga-autobots-elk-471850042218-logsstac-trailbucket-rk21t6aox8cf\n",
      "2019-09-03 00:55:08 ga-config-471850042218\n",
      "2017-08-31 22:23:35 ga-odc-eros-archive-west\n",
      "2019-05-02 17:11:57 ga-odc-eros-kops-west\n",
      "2018-07-25 07:15:30 guarddutyslacklambda-471850042218\n",
      "2019-10-16 04:41:24 guarddutyteamslambda-471850042218\n",
      "2017-05-26 00:29:35 lcmap-washington-state\n",
      "2018-02-07 22:28:56 usgs-devs-tfstate\n"
     ]
    }
   ],
   "source": [
    "! /notebooks/.local/bin/aws s3 ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eodatasets3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DatasetAssembler',\n",
       " 'IfExists',\n",
       " 'REPO_URL',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " '_version',\n",
       " 'absolute_import',\n",
       " 'assemble',\n",
       " 'documents',\n",
       " 'images',\n",
       " 'model',\n",
       " 'properties',\n",
       " 'serialise',\n",
       " 'ui',\n",
       " 'utils',\n",
       " 'validate',\n",
       " 'verify']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(eodatasets3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module eodatasets3.assemble in eodatasets3:\n",
      "\n",
      "NAME\n",
      "    eodatasets3.assemble - API for easily writing an ODC Dataset\n",
      "\n",
      "CLASSES\n",
      "    builtins.Exception(builtins.BaseException)\n",
      "        AssemblyError\n",
      "        IncompleteDatasetError\n",
      "    builtins.UserWarning(builtins.Warning)\n",
      "        DatasetCompletenessWarning\n",
      "    enum.Enum(builtins.object)\n",
      "        IfExists\n",
      "    eodatasets3.properties.EoFields(builtins.object)\n",
      "        DatasetAssembler\n",
      "    \n",
      "    class AssemblyError(builtins.Exception)\n",
      "     |  Common base class for all non-exit exceptions.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      AssemblyError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class DatasetAssembler(eodatasets3.properties.EoFields)\n",
      "     |  Convenient access fields for the most common/essential properties in datasets\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DatasetAssembler\n",
      "     |      eodatasets3.properties.EoFields\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self) -> 'DatasetAssembler'\n",
      "     |  \n",
      "     |  __exit__(self, exc_type, exc_val, exc_tb)\n",
      "     |  \n",
      "     |  __init__(self, collection_location:Union[pathlib.Path, NoneType]=None, dataset_location:Union[pathlib.Path, str, NoneType]=None, metadata_path:Union[pathlib.Path, NoneType]=None, dataset_id:Union[uuid.UUID, NoneType]=None, if_exists:eodatasets3.assemble.IfExists=<IfExists.ThrowError: 2>, allow_absolute_paths:bool=False, naming_conventions:str='default') -> None\n",
      "     |      Assemble a dataset with ODC metadata, writing metadata and (optionally) its imagery as COGs.\n",
      "     |      \n",
      "     |      There are three optional paths that can be specified. At least one must be.\n",
      "     |      \n",
      "     |      - A *collection path* is the root folder where datasets will live (in sub-[sub]-folders).\n",
      "     |      - Each dataset has its own *dataset location*, as stored in an Open Data Cube index.\n",
      "     |        All paths inside the metadata are relative to this location.\n",
      "     |      - An output metadata document location.\n",
      "     |      \n",
      "     |      If you're writing data, you typically only need to specify the collection path, and the others\n",
      "     |      will be automatically generated using the naming conventions.\n",
      "     |      \n",
      "     |      If you're only writing a metadata file (for existing data), you only need to specify a metadata path.\n",
      "     |      \n",
      "     |      If you're storing data using an exotic URI schema, such as a 'tar://' URL path, you will need to specify\n",
      "     |      this as your dataset location.\n",
      "     |      \n",
      "     |      :param collection_location:\n",
      "     |          Optional base directory where the collection of datasets should live. Subfolders will be\n",
      "     |          created accordion to the naming convention.\n",
      "     |      :param dataset_location:\n",
      "     |          Optional location for this specific dataset. Otherwise it will be generated according to the collection\n",
      "     |          path and naming conventions.\n",
      "     |      :param metadata_path:\n",
      "     |          Optional metadata document output path. Otherwise it will be generated according to the collection path\n",
      "     |          and naming conventions.\n",
      "     |      :param dataset_id:\n",
      "     |          Optional UUID for this dataset, otherwise a random only will be created. Use this if you have a stable\n",
      "     |          way of generating your own IDs.\n",
      "     |      :param if_exists:\n",
      "     |          What to do if the output dataset already exists? By default, throw an error.\n",
      "     |      :param allow_absolute_paths:\n",
      "     |          Allow metadata paths to refer to files outside the dataset location. this means they will have to be\n",
      "     |          absolute paths, and not be portable. (default: False)\n",
      "     |      :param naming_conventions:\n",
      "     |          Naming conventions to use. Supports `default` or `dea`. The latter has stricter metadata requirements\n",
      "     |          (try it and see -- it will tell your what's missing).\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name:str, value:Any) -> None\n",
      "     |      Prevent the accident of setting new properties on the assembler (it has happened multiple times).\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  add_accessory_file(self, name:str, path:pathlib.Path)\n",
      "     |      Record a reference to an additional file. Such as native metadata, thumbnails,\n",
      "     |      checksums, etc. Anything other than ODC measurements.\n",
      "     |      \n",
      "     |      By convention, the name should have prefixes with their category, such as\n",
      "     |      'metadata:' or 'thumbnail:'\n",
      "     |      \n",
      "     |      :param name: identifying name, eg 'metadata:mtl'\n",
      "     |      :param path: local path to file.\n",
      "     |  \n",
      "     |  add_source_dataset(self, dataset:eodatasets3.model.DatasetDoc, classifier:Union[str, NoneType]=None, auto_inherit_properties:bool=False)\n",
      "     |      Record a source dataset using its metadata document.\n",
      "     |      \n",
      "     |      It can optionally copy common properties from the source dataset (platform, instrument etc)/\n",
      "     |      \n",
      "     |      (see self.INHERITABLE_PROPERTIES for the list of fields that are inheritable)\n",
      "     |      \n",
      "     |      :param dataset:\n",
      "     |      :param auto_inherit_properties: Whether to copy any common properties from the dataset\n",
      "     |      \n",
      "     |      :param classifier: How to classify the kind of source dataset. This is will automatically\n",
      "     |                         be filled with the family of dataset if available (eg. \"level1\").\n",
      "     |      \n",
      "     |                         You want to set this if you have two datasets of the same type that\n",
      "     |                         are used for different purposes. Such as having a second level1 dataset\n",
      "     |                         that was used for QA (but is not this same scene).\n",
      "     |      \n",
      "     |      \n",
      "     |      See :func:`add_source_path` if you have a filepath reference instead of a document.\n",
      "     |  \n",
      "     |  add_source_path(self, *paths:pathlib.Path, classifier:str=None, auto_inherit_properties:bool=False)\n",
      "     |      Record a source dataset using the path to its metadata document.\n",
      "     |      \n",
      "     |      :param paths:\n",
      "     |      \n",
      "     |      See other parameters in :func:`DatasetAssembler.add_source_dataset`\n",
      "     |  \n",
      "     |  cancel(self)\n",
      "     |      Cancel the package, cleaning up temporary files.\n",
      "     |      \n",
      "     |      This works like :func:`DatasetAssembler.close`, but is intentional, so no warning will\n",
      "     |      be raised for forgetting to complete the package first.\n",
      "     |  \n",
      "     |  close(self)\n",
      "     |      Clean up any temporary files, even if dataset has not been written\n",
      "     |  \n",
      "     |  done(self, validate_correctness:bool=True, sort_measurements:bool=True) -> Tuple[uuid.UUID, pathlib.Path]\n",
      "     |      Write the dataset and move it into place.\n",
      "     |      \n",
      "     |      It will be validated, metadata will be written, and if all is correct, it will be\n",
      "     |      moved to the output location.\n",
      "     |      \n",
      "     |      The final move is done atomically, so the dataset will only exist in the output\n",
      "     |      location if it is complete.\n",
      "     |      \n",
      "     |      :param validate_correctness: Run the eo3-validator on the resulting metadata.\n",
      "     |      :param sort_measurements: Order measurements alphabetically. (instead of insert-order)\n",
      "     |      :raises: :class:`IncompleteDatasetError` If any critical metadata is incomplete.\n",
      "     |      \n",
      "     |      :returns: The id and final path to the dataset metadata file.\n",
      "     |  \n",
      "     |  extend_user_metadata(self, section_name:str, doc:Dict[str, Any])\n",
      "     |      Record extra metadata from the processing of the dataset.\n",
      "     |      \n",
      "     |      It can be any document suitable for yaml/json serialisation, and will be written into\n",
      "     |      the sidecar \"proc-info\" metadata.\n",
      "     |      \n",
      "     |      This is typically used for recording processing parameters or environment information.\n",
      "     |      \n",
      "     |      :param section_name: Should be unique to your product, and identify the kind of document,\n",
      "     |                           eg 'brdf_ancillary'\n",
      "     |      :param doc: Document\n",
      "     |  \n",
      "     |  iter_measurement_paths(self) -> Generator[Tuple[eodatasets3.images.GridSpec, str, pathlib.Path], NoneType, NoneType]\n",
      "     |      *not recommended* - will likely change soon.\n",
      "     |      \n",
      "     |      Iterate through the list of measurement names that have been written, and their current (temporary) paths.\n",
      "     |      \n",
      "     |      TODO: Perhaps we want to return a real measurement structure here as it's not very extensible.\n",
      "     |  \n",
      "     |  note_measurement(self, name, path:Union[pathlib.Path, str], expand_valid_data=True, relative_to_dataset_location=False)\n",
      "     |      Reference a measurement from its existing file path.\n",
      "     |      \n",
      "     |      (no data is copied, but Geo information is read from it.)\n",
      "     |      \n",
      "     |      :param name:\n",
      "     |      :param path:\n",
      "     |      :param expand_valid_data:\n",
      "     |      :param relative_to_dataset_location:\n",
      "     |  \n",
      "     |  note_software_version(self, name:str, url:str, version:str)\n",
      "     |      Record the version of some software used to produce the dataset.\n",
      "     |      \n",
      "     |      :param name: a short human-readable name for the software. eg \"datacube-core\"\n",
      "     |      :param url: A URL where the software is found, such as the git repository.\n",
      "     |      :param version: the version string, eg. \"1.0.0b1\"\n",
      "     |  \n",
      "     |  write_measurement(self, name:str, path:Union[pathlib.Path, str], overviews:Iterable[int]=(8, 16, 32), overview_resampling:rasterio.enums.Resampling=<Resampling.average: 5>, expand_valid_data:bool=True, file_id:str=None)\n",
      "     |      Write a measurement by copying it from a file path.\n",
      "     |      \n",
      "     |      Assumes the file is gdal-readable.\n",
      "     |      \n",
      "     |      :param name: Identifier for the measurement eg ``'blue'``.\n",
      "     |      :param path:\n",
      "     |      :param overviews: Set of overview sizes to write\n",
      "     |      :param overview_resampling: rasterio Resampling method to use\n",
      "     |      :param expand_valid_data: Include this measurement in the valid-data geometry of the metadata.\n",
      "     |      :param file_id: Optionally, how to identify this in the filename instead of using the name.\n",
      "     |                      (DEA has measurements called ``blue``, but their written filenames must be ``band04`` by\n",
      "     |                      convention.)\n",
      "     |  \n",
      "     |  write_measurement_numpy(self, name:str, array:numpy.ndarray, grid_spec:eodatasets3.images.GridSpec, nodata=None, overviews=(8, 16, 32), overview_resampling=<Resampling.average: 5>, expand_valid_data=True, file_id:str=None)\n",
      "     |      Write a measurement from a numpy array and grid spec.\n",
      "     |      \n",
      "     |      The most common case is to copy the grid spec from your input dataset,\n",
      "     |      assuming you haven't reprojected.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          p.write_measurement_numpy(\n",
      "     |              \"blue\",\n",
      "     |              new_array,\n",
      "     |              GridSpec.from_dataset_doc(source_dataset),\n",
      "     |              nodata=-999,\n",
      "     |          )\n",
      "     |      \n",
      "     |      See :func:`write_measurement` for other parameters.\n",
      "     |      \n",
      "     |      :param array:\n",
      "     |      :param grid_spec:\n",
      "     |      :param nodata:\n",
      "     |  \n",
      "     |  write_measurement_rio(self, name:str, ds:rasterio.io.DatasetReader, overviews=(8, 16, 32), overview_resampling=<Resampling.average: 5>, expand_valid_data=True, file_id=None)\n",
      "     |      Write a measurement by reading it an open rasterio dataset\n",
      "     |      \n",
      "     |      :param ds: An open rasterio dataset\n",
      "     |      \n",
      "     |      See :func:`write_measurement` for other parameters.\n",
      "     |  \n",
      "     |  write_measurements_odc_xarray(self, dataset:xarray.core.dataset.Dataset, nodata:int, overviews=(8, 16, 32), overview_resampling=<Resampling.average: 5>, expand_valid_data=True, file_id=None)\n",
      "     |      Write measurements from an ODC xarray.Dataset\n",
      "     |      \n",
      "     |      The main requirement is that the Dataset contains a CRS attribute\n",
      "     |      and X/Y or lat/long dimensions and coordinates. These are used to\n",
      "     |      create an ODC GeoBox.\n",
      "     |      \n",
      "     |      :param dataset: an xarray dataset (as returned by ``dc.load()`` and other methods)\n",
      "     |      \n",
      "     |      See :func:`write_measurement` for other parameters.\n",
      "     |  \n",
      "     |  write_thumbnail(self, red:str, green:str, blue:str, resampling:rasterio.enums.Resampling=<Resampling.average: 5>, static_stretch:Tuple[int, int]=None, percentile_stretch:Tuple[int, int]=(2, 98), scale_factor:int=10, kind:str=None)\n",
      "     |      Write a thumbnail for the dataset using the given measurements (specified by name) as r/g/b.\n",
      "     |      \n",
      "     |      (the measurements must already have been written.)\n",
      "     |      \n",
      "     |      A linear stretch is performed on the colour. By default this is a dynamic 2% stretch\n",
      "     |      (the 2% and 98% percentile values of the input). The static_stretch parameter will\n",
      "     |      override this with a static range of values.\n",
      "     |      \n",
      "     |      \n",
      "     |      :param red: Name of measurement to put in red band\n",
      "     |      :param green: Name of measurement to put in green band\n",
      "     |      :param blue: Name of measurement to put in blue band\n",
      "     |      :param kind: If you have multiple thumbnails, you can specify the 'kind' name to distinguish\n",
      "     |                   them (it will be put in the filename).\n",
      "     |                   Eg. GA's ARD has two thumbnails, one of kind ``nbar`` and one of ``nbart``.\n",
      "     |      :param scale_factor: How many multiples smaller to make the thumbnail.\n",
      "     |      :param percentile_stretch: Upper/lower percentiles to stretch by\n",
      "     |      :param resampling: rasterio :class:`rasterio.enums.Resampling` method to use.\n",
      "     |      :param static_stretch: Use a static upper/lower value to stretch by instead of dynamic stretch.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  label\n",
      "     |      An optional displayable string to identify this dataset.\n",
      "     |      \n",
      "     |      These are often used when when presenting a list of datasets, such as in search results or a filesystem folder.\n",
      "     |      They are unstructured, but should be more humane than showing a list of UUIDs.\n",
      "     |      \n",
      "     |      By convention they have no spaces, due to their usage in filenames.\n",
      "     |      \n",
      "     |      Eg. ``ga_ls5t_ard_3-0-0_092084_2009-12-17_final`` or USGS's ``LT05_L1TP_092084_20091217_20161017_01_T1``\n",
      "     |      \n",
      "     |      A label will be auto-generated using the naming-conventions, but you can manually override it by\n",
      "     |      setting this property.\n",
      "     |  \n",
      "     |  properties\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  INHERITABLE_PROPERTIES = {'datetime', 'eo:cloud_cover', 'eo:gsd', 'eo:...\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from eodatasets3.properties.EoFields:\n",
      "     |  \n",
      "     |  processed_now(self)\n",
      "     |      Shorthand for when the dataset was processed right now on the current system.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from eodatasets3.properties.EoFields:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  dataset_version\n",
      "     |      The version of the dataset.\n",
      "     |      \n",
      "     |      Typically digits separated by a dot. Eg. '1.0.0'\n",
      "     |      \n",
      "     |      The first digit is usually the collection number for\n",
      "     |      this 'producer' organisation, such as USGS Collection 1 or\n",
      "     |      GA Collection 3.\n",
      "     |  \n",
      "     |  datetime\n",
      "     |      The searchable date and time of the assets. (Default to UTC if not specified)\n",
      "     |  \n",
      "     |  datetime_range\n",
      "     |      An optional date range for the dataset.\n",
      "     |      \n",
      "     |      The `datetime` is still mandatory when this is set.\n",
      "     |      \n",
      "     |      This field is a shorthand for reading/setting the datetime-range\n",
      "     |      stac extension properties: 'dtr:start_datetime' and 'dtr:end_datetime'\n",
      "     |  \n",
      "     |  instrument\n",
      "     |      Name of instrument or sensor used (e.g., MODIS, ASTER, OLI, Canon F-1).\n",
      "     |      \n",
      "     |      Shorthand for 'eo:instrument' property\n",
      "     |  \n",
      "     |  maturity\n",
      "     |      The dataset maturity. The same data may be processed multiple times -- becoming more\n",
      "     |      mature -- as new ancillary data becomes available.\n",
      "     |      \n",
      "     |      Typical values (from least to most mature): \"nrt\", \"interim\", \"final\"\n",
      "     |  \n",
      "     |  platform\n",
      "     |      Unique name of the specific platform the instrument is attached to.\n",
      "     |      \n",
      "     |      For satellites this would be the name of the satellite (e.g., landsat-8, sentinel-2A),\n",
      "     |      whereas for drones this would be a unique name for the drone.\n",
      "     |      \n",
      "     |      Shorthand for 'eo:platform' property\n",
      "     |  \n",
      "     |  processed\n",
      "     |      When the dataset was processed (Default to UTC if not specified)\n",
      "     |      \n",
      "     |      Shorthand for the 'odc:processing_datetime' field\n",
      "     |  \n",
      "     |  producer\n",
      "     |      Organisation that produced the data.\n",
      "     |      \n",
      "     |      eg. usgs.gov or ga.gov.au\n",
      "     |      \n",
      "     |      Shorthand for 'odc:producer' property\n",
      "     |  \n",
      "     |  product_family\n",
      "     |      The identifier for this \"family\" of products, such as 'ard', 'level1` or 'fc'.\n",
      "     |      It's used for grouping similar products together.\n",
      "     |      \n",
      "     |      They products in a family are usually produced the same way but have small variations:\n",
      "     |      they come from different sensors, or are written in different projections, etc.\n",
      "     |      \n",
      "     |      'ard' family of products: 'ls7_ard', 'ls5_ard' ....\n",
      "     |      \n",
      "     |      On older versions of opendatacube this was called \"product_type\".\n",
      "     |      \n",
      "     |      Shorthand for 'odc:product_family' property.\n",
      "     |  \n",
      "     |  region_code\n",
      "     |      The \"region\" of acquisition. This is a platform-agnostic representation of things like\n",
      "     |      the Landsat Path+Row. Datasets with the same Region Code will *roughly* (but usually\n",
      "     |      not *exactly*) cover the same spatial footprint.\n",
      "     |      \n",
      "     |      It's generally treated as an opaque string to group datasets and process as stacks.\n",
      "     |      \n",
      "     |      For Landsat products it's the concatenated '{path}{row}' (both numbers formatted to three digits).\n",
      "     |      \n",
      "     |      For Sentinel 2, it's the MGRS grid (TODO presumably?).\n",
      "     |      \n",
      "     |      Shorthand for 'odc:region_code' property.\n",
      "    \n",
      "    class DatasetCompletenessWarning(builtins.UserWarning)\n",
      "     |  A non-critical warning for invalid or incomplete metadata\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DatasetCompletenessWarning\n",
      "     |      builtins.UserWarning\n",
      "     |      builtins.Warning\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, validation:eodatasets3.validate.ValidationMessage) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __str__(self) -> str\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.UserWarning:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class IfExists(enum.Enum)\n",
      "     |  An enumeration.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      IfExists\n",
      "     |      enum.Enum\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Overwrite = <IfExists.Overwrite: 1>\n",
      "     |  \n",
      "     |  Skip = <IfExists.Skip: 0>\n",
      "     |  \n",
      "     |  ThrowError = <IfExists.ThrowError: 2>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from enum.Enum:\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the Enum member.\n",
      "     |  \n",
      "     |  value\n",
      "     |      The value of the Enum member.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from enum.EnumMeta:\n",
      "     |  \n",
      "     |  __members__\n",
      "     |      Returns a mapping of member name->value.\n",
      "     |      \n",
      "     |      This mapping lists all enum members, including aliases. Note that this\n",
      "     |      is a read-only view of the internal mapping.\n",
      "    \n",
      "    class IncompleteDatasetError(builtins.Exception)\n",
      "     |  Common base class for all non-exit exceptions.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      IncompleteDatasetError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, validation:eodatasets3.validate.ValidationMessage) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "\n",
      "DATA\n",
      "    Any = typing.Any\n",
      "    Location = typing.Union[pathlib.Path, str]\n",
      "    Optional = typing.Optional\n",
      "\n",
      "FILE\n",
      "    /usr/local/lib/python3.6/dist-packages/eodatasets3/assemble.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(eodatasets3.assemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
